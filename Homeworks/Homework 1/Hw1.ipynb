{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "711f14c9",
   "metadata": {
    "id": "711f14c9"
   },
   "source": [
    "```\n",
    "BEGIN ASSIGNMENT\n",
    "run_tests: true\n",
    "requirements: requirements.txt\n",
    "init_cell: false\n",
    "check_all_cell: false\n",
    "export_cell: false\n",
    "generate:\n",
    "    points: 50\n",
    "    pdf: true\n",
    "    pdfs:\n",
    "        course_id: 'CS-UY 4563'\n",
    "        assignment_id: 'HW1_prog'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c4b296",
   "metadata": {
    "id": "d8c4b296"
   },
   "source": [
    "# Programming Assignment 1:    Implementing Multiple Linear Regression Using Gradient Descent And Normal Equations.  Optional: Stochastic Gradient Descent Algorithm.\n",
    "\n",
    "In this assignment you will use the California census data to build a model using linear regression to predict the housing prices in California.\n",
    "\n",
    "This is a supervised machine learning task. \n",
    "\n",
    "The features are:\n",
    "* median income in block group\n",
    "*  median house age in block group\n",
    "* average number of rooms per household\n",
    "* average number of bedrooms per household\n",
    "* block group population\n",
    "* average number of household members\n",
    "* block group latitude\n",
    "* block group longitude\n",
    "\n",
    "The target is to predict the median house price in a block. \"A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data.\"  Your cost function is RSS.\n",
    "\n",
    "In this assignment, you will load data, plot data, perform simple mathematical manipulations, and fit a linear regression model. The assignment uses the California housing data set, a widely-used machine learning data set for illustrating basic concepts.  You will:\n",
    "* read the data and perform some preprocessing steps\n",
    "* visually observe the data set\n",
    "* compute  the coefficients/weights ${\\bf w}$ using the gradient descent algorithm (a local optimizer) \n",
    "* compute ${\\bf w}$ (again) this time using the normal equation (a global optimizer). You will compare the $\\bf w$'s you recived from both algorithms.\n",
    "* You will then compute the $R^2$ value by first computing $\\hat{\\bf y}, RSS$ and $TSS$.\n",
    "\n",
    "We have done some of the steps for you.\n",
    "\n",
    "Please add your own print statements to check your code to ensure your code It is correct in every step. (Note: we will not be grading the print statements you add to your code.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6965906e",
   "metadata": {
    "id": "6965906e"
   },
   "source": [
    "## Before you start\n",
    "\n",
    "For this semester, the teaching staff of this course will be using Autograder to grade programming assignment. Here are three things we would like you to know before starting. `PLEASE READ CAREFULLY.` Otherwise, you might not receive grades for some questions.\n",
    "\n",
    "* If you see any blocks containing statements like `grader.check(\"Qxx\")`, please `DO NOT MODIFY` them. You can add new cells to the notebook, but just make sure there is `NO OTHER CELLS` between the answer cells containing tag `# TODO Qxx` and grading cells like 'grader.check(\"Qxx\")`. \n",
    "\n",
    "* If the instructions say that you are required to use certain names for output variables, please `FOLLOW THE instructions`. You can still create new variables, but just the make sure to `ASSIGN THE OUTPUT VARIABLES TO CORRECT VALUES`. \n",
    "\n",
    "* Some of the print statements are in the comments(print in Q17 and Q18 for example). Please feel free to use them, but you must `PUT THESE PRINT STATEMENTS IN COMMENTS` before you submit the programming assignment.\n",
    "\n",
    "* Please `APPEND YOUR NYU NETID` to the name your submission (for example, name your submission as \"HW1_prog_abc12345.ipynb\" when you submit on Gradescope, and replace <abc1234> with your NYU NetID). \n",
    "\n",
    "The autograder does not account for all test cases and edge cases, meaning that it is possible to receive a different grade than what the Autograder assigns you. The teaching staff will grade all submissions manually. Thank you very much for your understanding, and good luck with programming assignment 1!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97236d4",
   "metadata": {
    "id": "e97236d4"
   },
   "source": [
    "## Load the standard packages for working with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507dca73",
   "metadata": {
    "id": "507dca73"
   },
   "outputs": [],
   "source": [
    "# run this code cell using shift+enter before moving further.   You will be writing the algorithm from scratch, but these standard packages will make your work cleaner and faster. \n",
    "\n",
    "import numpy as np # library which more efficiently allows you to work with large multidimensional arrays and matrices.  It has functions that operate on the arrays/matrices\n",
    "import pandas as pd # built on numpy.  Makes it easier to read in data and clean data among other things\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing # We will be using one of SKlearn's datasets\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler # Scaling is suggested when running a gradient descent algorithm\n",
    "\n",
    "import matplotlib # a plotting library\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d1e3a6",
   "metadata": {
    "id": "e7d1e3a6"
   },
   "source": [
    "## Loading the data\n",
    "\n",
    "Here is some more information about the dataset.  The California housing data set was collected in 1990 to study the relationship between median house price and various factors.  Since the variables are easy to understand, the data set is ideal for learning basic concepts in machine learning. This is one of the datasets that can be downloaded from scikit-learn.  You can learn about this dataset at https://inria.github.io/scikit-learn-mooc/python_scripts/datasets_california_housing.html\n",
    "\n",
    "Here is a brief description of the dataset provided by scikit-learn:\n",
    ">The target variable is the median house value for California districts,\n",
    "expressed in hundreds of thousands of dollars ($100,000).\n",
    "\n",
    ">This dataset was derived from the 1990 U.S. census, using one row per census\n",
    "block group. A block group is the smallest geographical unit for which the U.S.\n",
    "Census Bureau publishes sample data (a block group typically has a population\n",
    "of 600 to 3,000 people).\n",
    "\n",
    ">An household is a group of people residing within a home. Since the average\n",
    "number of rooms and bedrooms in this dataset are provided per household, these\n",
    "columns may take surpinsingly large values for block groups with few households\n",
    "and many empty houses, such as vacation resorts. \n",
    "\n",
    "\n",
    "In the lab, you will complete all the code marked `TODO`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92023556",
   "metadata": {
    "id": "92023556"
   },
   "outputs": [],
   "source": [
    "california_housing = fetch_california_housing(as_frame=True)  # load the housing dataset. By setting as_frame=True, the data will be a DataFrame\n",
    "# To learn more about the interface - go to the official documentation https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html\n",
    "\n",
    "# loading the data matrix as a DataFrame\n",
    "data_df = california_housing.data\n",
    "# loading the target vector as a DataFrame\n",
    "target_df = california_housing.target\n",
    "\n",
    "# Storing the feature names to be used later\n",
    "feature_names = california_housing.feature_names\n",
    "\n",
    "# Looking at the first 6 lines of code\n",
    "print(data_df.head(6))\n",
    "print(target_df.head(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i4gxgMGaoO62",
   "metadata": {
    "id": "i4gxgMGaoO62"
   },
   "outputs": [],
   "source": [
    "# To read the description of the dataset, run the following line of code.\n",
    "print(california_housing['DESCR'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C4UBu7aF939Q",
   "metadata": {
    "id": "C4UBu7aF939Q"
   },
   "source": [
    "After loading the dataset, we should check for missing values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O0lDFBZr-MOO",
   "metadata": {
    "id": "O0lDFBZr-MOO"
   },
   "outputs": [],
   "source": [
    "# Check whether the dataset has any missing values.\n",
    "data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kKr6GqgD_DD_",
   "metadata": {
    "id": "kKr6GqgD_DD_"
   },
   "source": [
    "In this dataset, we are told in the description there are no missing values.\" There are two main methods if we miss any value for numerical attributes. The first way is to delete the database instance (one row or column) with a null value. The second way is to impute the missing value, like filling in the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e084b",
   "metadata": {
    "id": "3f4e084b"
   },
   "source": [
    "## Preparing the Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385d989e",
   "metadata": {
    "id": "385d989e"
   },
   "source": [
    "We haven't talked yet about splitting the dataset into train, validation and test so we won't be splitting the dataset in this assignment. In future assignments we would split the dataset before scaling the dataset.\n",
    "\n",
    "Since we are running gradient descent, we will scale the dataset (you should see what happens if we don't scale dataset before running gradient descent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e3a22d",
   "metadata": {
    "id": "63e3a22d"
   },
   "outputs": [],
   "source": [
    "# TODO Q01\n",
    "X= ...# converting the Pandas dataframe into a numpy array\n",
    "y= ... # Creating the vector y with the values in the column PRICE.\n",
    "\n",
    "scale=StandardScaler() # create the scaler object\n",
    "\n",
    "X_scaled = ...  # Type \"scale.fit_transform(X)\" here\n",
    "\n",
    "# Check the shape of X and y vectors.\n",
    "print(\"shape of X: \", X_scaled.shape)  # We have 20640 examples and 8 features\n",
    "print(\"shape of y: \", y.shape)  # Notice that y is a 1-D object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe06df0",
   "metadata": {
    "id": "afe06df0"
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935996b4",
   "metadata": {
    "id": "935996b4"
   },
   "source": [
    "Reshape y to be rank 2. After checking the shape of X and y in the above code cell, we see that X is already rank 2 but y is a rank 1 matrix. Before moving ahead, convert y to be rank 2 matrix. For example, I would use the command y = y.reshape(y.shape[0],1) to reshape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3420214d",
   "metadata": {
    "id": "3420214d"
   },
   "outputs": [],
   "source": [
    "# TODO Q02\n",
    "# Reshape y into a rank 2 matrix y_2d(<np.ndarray>)\n",
    "y_2d = ...\n",
    "print(\"shape of y_2d: \", y_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b6f976",
   "metadata": {
    "id": "46b6f976"
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118be59e",
   "metadata": {
    "id": "118be59e"
   },
   "source": [
    "Calculating the value of `N` i.e. number of training examples. \n",
    "Hint: Value of `N` is equal to the number of rows in either `X` or `y` matrix which can be accessed using numpy shape command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acfc100",
   "metadata": {
    "id": "1acfc100"
   },
   "outputs": [],
   "source": [
    "# TODO Q03\n",
    "# Save number of training examples into N and print it\n",
    "N = ...\n",
    "print(\"N: \", N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61104f8",
   "metadata": {
    "id": "e61104f8"
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YWpmkvcvrpS2",
   "metadata": {
    "id": "YWpmkvcvrpS2"
   },
   "source": [
    "Next, add a column of ones to the front of $X$:\n",
    "$$X=\\begin{bmatrix}\n",
    "1 & x^{(1)}_1 & \\cdots & x^{(1)}_8\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots\\\\\n",
    "1 & x^{(20640)}_1 & \\cdots & x^{(20640)}_8\\\\\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f865820",
   "metadata": {
    "id": "0f865820"
   },
   "outputs": [],
   "source": [
    "# TODO Q04\n",
    "# Create a column of ones and name it as ones, then append it to X using hstack, name the new matrix \n",
    "# X_1(<np.ndarray>)\n",
    "ones = ... \n",
    "X_1 =  ... \n",
    "print(\"X_1:\", X_1)\n",
    "\n",
    "# Shape of X_1 should be (20640, 9)\n",
    "print(\"shape of X_1: \", X_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8ce7b2",
   "metadata": {
    "id": "cf8ce7b2"
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be9f822",
   "metadata": {
    "id": "4be9f822"
   },
   "source": [
    "Lets explore the housing prices \n",
    "\n",
    "Use the response vector `y` to find the mean house price in thousands and the fraction of blocks that are above \\$300,000.\n",
    "\n",
    " Remember that: \"The target variable is the median house value for California districts,\n",
    "expressed in hundreds of thousands of dollars ($100,000).\" \n",
    "\n",
    "Create print statements of the form:\n",
    "\n",
    "    The mean house price is xx.yy thousands of dollars.\n",
    "    Only x.y percent are above $300,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w-oij43rFD1t",
   "metadata": {
    "id": "w-oij43rFD1t"
   },
   "outputs": [],
   "source": [
    "# TODO Q05\n",
    "mean_house_price = ... # find the mean house price here\n",
    "percent_over_300000 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M--N0GZncnRS",
   "metadata": {
    "id": "M--N0GZncnRS"
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TAeGXfnwFaQ_",
   "metadata": {
    "id": "TAeGXfnwFaQ_"
   },
   "outputs": [],
   "source": [
    "# Print statements for mean_house_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DbO6dBmMFOyP",
   "metadata": {
    "id": "DbO6dBmMFOyP"
   },
   "source": [
    "#### If done correctly: The mean house price is 206,855.82 dollars. Only 18.59 percent are above $300,000.  (These numbers were rounded - so to check your answer, you need to round as well.)\n",
    "#### And please notice that the database uses a different unit, so the print output should be 2.0685582 (rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8376ef97",
   "metadata": {
    "id": "8376ef97"
   },
   "source": [
    "## Visualizing the data\n",
    "\n",
    "Python's `matplotlib` has very good routines for plotting and visualizing data that closely follow the format of MATLAB programs. \n",
    "(Note: in future programs, we will separate the data into a training set, validation set, and test set before we do any data exploration)\n",
    "\n",
    "Next, we plot the relationship between the house price and each of our scaled features.\n",
    "\n",
    "You might notice that some of the features are skewed to one side.  There are techniques for addressing this that you can read about on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b57dbe",
   "metadata": {
    "id": "b6b57dbe"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(10,10)) \n",
    "\n",
    "# top row\n",
    "axs[0, 0].scatter(X_1[:,1],y, s=1)\n",
    "axs[0, 0].set_xlabel(feature_names[0])\n",
    "axs[0, 1].scatter(X_1[:,2],y, s=1)\n",
    "axs[0, 1].set_xlabel(feature_names[1])\n",
    "axs[0, 2].scatter(X_1[:,3],y, s=1)\n",
    "axs[0, 2].set_xlabel(feature_names[2])\n",
    "axs[0, 3].scatter(X_1[:,4],y, s=1)\n",
    "axs[0, 3].set_xlabel(feature_names[3])\n",
    "\n",
    "# bottom row\n",
    "axs[1, 0].scatter(X_1[:,5],y, s=1)\n",
    "axs[1, 0].set_xlabel(feature_names[4])\n",
    "axs[1, 1].scatter(X_1[:,6],y, s=1)\n",
    "axs[1, 1].set_xlabel(feature_names[5])\n",
    "axs[1, 2].scatter(X_1[:,7],y, s=1)\n",
    "axs[1, 2].set_xlabel(feature_names[6])\n",
    "axs[1, 3].scatter(X_1[:,8],y, s=1)\n",
    "axs[1, 3].set_xlabel(feature_names[7])\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set( ylabel='Price')\n",
    "    \n",
    "fig.tight_layout()\n",
    "\n",
    "# This code could have been written more complactly as follows:\n",
    "#for i in range (0,2):\n",
    "#  for j in range (0,4):\n",
    "#    axs[i, j].scatter(X_1[:,i*4+j+1],y, s=1)\n",
    "#    axs[i, j].set_xlabel(feature_names[i*4+j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dc0dba",
   "metadata": {
    "id": "45dc0dba"
   },
   "source": [
    "By looking at the graphs, we can notice that only MedInc has a strong correlation with the price.  To have a more formal notion of how housing price relates to each feature we compute the standard correlation coefficient.\n",
    "\n",
    "We will use one of the Panda functions to do this.  Thus we use the dataframes target_df and data_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TYxJvYbI1qFf",
   "metadata": {
    "id": "TYxJvYbI1qFf"
   },
   "outputs": [],
   "source": [
    "data_df[feature_names].corrwith(target_df, axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e86e56",
   "metadata": {
    "id": "65e86e56"
   },
   "source": [
    " We can visualize how correlated our features are with each other.  We will use the Pandas `scatter_matrix()` function.  (Pandas have some useful plotting functions.  Note we are using `data_df` here instead of $X_1$.  \n",
    "\n",
    " We are using the unscaled features here so you can see the reason we scaled the dataset.  \n",
    "\n",
    "Note that down the diagonal, a histogram has been printed of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ad5148",
   "metadata": {
    "id": "75ad5148"
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(data_df[['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']], figsize=(12, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1006e0",
   "metadata": {
    "id": "fd1006e0"
   },
   "source": [
    "# Implementing Linear Regression Using Gradient Descent \n",
    "\n",
    "In this programming assigment (lab), you will be implementing the Linear Regression Model. We will be using the gradient descent algorithm (GDA) to minimize the cost function we discussed in class.  You have the option to also implement the stochastic gradient descent algorithm (SGDA) to minimize the cost function at the end of this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20f48d7",
   "metadata": {
    "id": "c20f48d7"
   },
   "source": [
    "## Cost Function.\n",
    "Compute the cost:$$J({\\bf w})=\\frac{1}{2N}\\sum_{i=1}^N(\\hat{y}^{(i)}-y^{(i)})^2$$\n",
    "\n",
    " Write the code to compute the cost inside the function. \n",
    "\n",
    "\n",
    "\n",
    "Do not change the function name or function parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52be956",
   "metadata": {
    "id": "a52be956"
   },
   "outputs": [],
   "source": [
    "# TODO Q06\n",
    "def compute_cost(X_1, y, w, N):\n",
    "    # Write your code in place of ellipsis. Cost can be calculated using a single line of code.\n",
    "    # Remember w is a vector here.\n",
    "    cost= ...\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad3baa",
   "metadata": {
    "id": "9fad3baa"
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q06\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf04403",
   "metadata": {
    "id": "ddf04403"
   },
   "source": [
    "Before moving ahead, ensure that the code you have written to compute the cost is correct. Just run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa46a937",
   "metadata": {
    "id": "fa46a937"
   },
   "outputs": [],
   "source": [
    "w_testcase=np.zeros((9,1))\n",
    "cost_verify= compute_cost(X_1, y_2d, w_testcase, N)\n",
    "print(\"cost_verify: \", cost_verify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81622fa",
   "metadata": {
    "id": "b81622fa"
   },
   "source": [
    "Your output should be equal to 2.8052415994936264. If it's equal to this, then move ahead. Else, re-check your code and re-verify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db975f81",
   "metadata": {
    "id": "db975f81"
   },
   "source": [
    "## Gradient Descent\n",
    "Write the code to perform gradient descent in the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bab92b3",
   "metadata": {
    "id": "0bab92b3"
   },
   "outputs": [],
   "source": [
    "# TODO Q07\n",
    "def gradient_descent(X_1 , y , learning_rate , w , n , num_iters):\n",
    "    # In place of ellipsis, write the updated value of w0 in temp0 and of w1 in temp1\n",
    "    # Finish the gradient descent function\n",
    "    for i in range(num_iters):\n",
    "        # derivative vector is given by : X_train.Transpose *  (( X_train * w)- y ) \n",
    "        # You may add your own variables\n",
    "        w = ...\n",
    "\n",
    "        if(i%100==0):\n",
    "            # In place of ellipsis, call the cost you just coded above\n",
    "            cost= ...\n",
    "\n",
    "            # You can uncomment print statements below to see how cost changes, \n",
    "            # but please make sure you put prints in comments before submission\n",
    "            # print(\"Cost\")\n",
    "            # print(cost)\n",
    "            \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3091caf",
   "metadata": {
    "id": "e3091caf"
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d98de3f",
   "metadata": {
    "id": "7d98de3f"
   },
   "source": [
    "Before moving ahead, ensure that your code to update $\\bf w$ is correct. Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ccb2c",
   "metadata": {
    "id": "5b3ccb2c"
   },
   "outputs": [],
   "source": [
    "w_testcase = np.zeros((9,1))\n",
    "g = gradient_descent(X_1, y_2d, 0.01, w_testcase, N, 10000)\n",
    "print(\"g[0]: \", g[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ebbd67",
   "metadata": {
    "id": "69ebbd67"
   },
   "source": [
    "The last cost should be: 0.26216121644573653. If it matches your out, then your code is likely to be correct. Otherwise, re-check your code and re-verify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4674d4e",
   "metadata": {
    "id": "c4674d4e"
   },
   "source": [
    "## Integrating the Batch Gradient Descent Function \n",
    "\n",
    "Integrating the above function into a single function multiple_linear_reg_model_gda: This function uses gradient descent algorithm to minimize the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1010f98",
   "metadata": {
    "id": "b1010f98"
   },
   "outputs": [],
   "source": [
    "# TODO 08\n",
    "# Complete the function\n",
    "def multiple_linear_reg_model_gda(X_1 , y , n , learning_rate , num_iters):\n",
    "\n",
    "    #initialize the values of parameter vector w. It should be a column vector of zeros of dimension(d+1,1)\n",
    "    w = ...\n",
    "\n",
    "    #calculate the initial cost by calling the function you coded above.\n",
    "    initial_cost= ...\n",
    "    print(\"Initial Cost\")\n",
    "    print(initial_cost)\n",
    "\n",
    "    #calculate the optimized value of gradients by calling the gradient_descent function coded above \n",
    "    w = ...\n",
    "    \n",
    "    # Calculate the cost with the optimized value of w0 and w1 by calling the cost function.    \n",
    "    final_cost = ...\n",
    "    print(\"Final Cost\")\n",
    "    print(final_cost)\n",
    "    \n",
    "    return w, initial_cost, final_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee61a1e6",
   "metadata": {
    "id": "ee61a1e6"
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q08\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a80bd06",
   "metadata": {
    "id": "6a80bd06"
   },
   "source": [
    "Now, when you have coded `multiple_linear_reg_model_gda` function, you can call this function to find the optimized values of parameters `w`. Before calling the function, set the values of `learning_rate` and `num_iters`. You may have to call this function several number of times with different values of num_iters and learning_rate to find the optimal values of `w`. For some values of `learning_rate`, it may give an error as the values of cost may reach a very high value(infinity) due to overshooting as discussed in the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7855a71",
   "metadata": {
    "id": "e7855a71"
   },
   "outputs": [],
   "source": [
    "# TODO Q09\n",
    "# Call the multiple_linear_reg_model_gda.\n",
    "learning_rate = ...\n",
    "num_iters = ...\n",
    "results = multiple_linear_reg_model_gda(X_1,y_2d, N, learning_rate, num_iters)\n",
    "\n",
    "w = results[0]\n",
    "print(\"w: \", w, \"\\ninitial cost: \", results[1], \"\\nfinal cost: \", results[2])\n",
    "\n",
    "# The value of final cost should be 0.26216115363575965 or nearly this(depending on the values of learning_rate and num_itersations you choose.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a3e5a",
   "metadata": {
    "id": "b14a3e5a"
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q09\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60de218e",
   "metadata": {
    "id": "60de218e"
   },
   "source": [
    "---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "You have finished the first part of the asssignment, feel free to take a break and come back to do the second part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21f03be",
   "metadata": {
    "id": "d21f03be"
   },
   "source": [
    "# Predicting the Median Price of a House in a Block\n",
    "\n",
    "Now you should have found (close to) the optimal values for `w0`, `w1`, `w2`, `w3`, ... `w8`.  Once you have the optimal values for the parameters, you can predict the value of `y` (median price) using `x` . Assume `x` has not yet be augmented with an extra `1`'.  Compute the function below to prdict `y`, using `x`, `w0` and `w1`, `w2`, `w3`, ..., `w8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38952fca",
   "metadata": {
    "id": "38952fca"
   },
   "outputs": [],
   "source": [
    "# TODO Q10\n",
    "# You can add an extra 1 to x or find some other solution for including the intercept (bias) term\n",
    "\n",
    "def predict(x, w_opt):\n",
    "    x_aug = ... \n",
    "    predicted_y = ...\n",
    "    \n",
    "    return predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MzukYxQPdqjS",
   "metadata": {
    "id": "MzukYxQPdqjS"
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d325963",
   "metadata": {
    "id": "6d325963"
   },
   "outputs": [],
   "source": [
    "# TODO Q11\n",
    "# Call the predict function with a new\n",
    "x = np.array([8, 41, 6, 1, 320, 2.5, 38, -122]) # Observe that x is not augmented with a one\n",
    "# To use our hypothesis, we must first scale x the same way we scaled the training data.\n",
    "\n",
    "# Before scaling, reshape x to be a 2-dimensional row vector (since our data matrix had each example as a row)\n",
    "x = ...\n",
    "# Next, we scale x as we scaled the training data\n",
    "x_scaled = scale.transform(x)\n",
    "\n",
    "# Finally, we can predict.\n",
    "y_predict = ... # SOLUTION\n",
    "print(\"The estimated house price is: \", y_predict*100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0vviwmkYfDhZ",
   "metadata": {
    "id": "0vviwmkYfDhZ"
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fce7b0",
   "metadata": {
    "id": "c4fce7b0"
   },
   "source": [
    "# Normal Equation Method\n",
    "Now, we will be writing the code to find the values of parameters `w` for our multiple linear regression model. This can also be used to cross-check the optimal values of $\\bf w$ we just found above using method above. These values should be same (or nearly same).\n",
    "Instead of writing the code for normal equation in one line, you can break this into parts. (Use `np.linalg.pinv`)\n",
    "\n",
    "Note : Do not append a column of ones in `X_1` because you have already done this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11815c50",
   "metadata": {
    "id": "11815c50"
   },
   "outputs": [],
   "source": [
    "# TODO Q12\n",
    "# Write the normal equation method, save the weights to w_vec(<np.ndarray>)\n",
    "\n",
    "w_vec = ...\n",
    "\n",
    "print(\"w_vec: \", w_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_DyRNJ9ofRgG",
   "metadata": {
    "id": "_DyRNJ9ofRgG"
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab92f66",
   "metadata": {
    "id": "7ab92f66"
   },
   "source": [
    "The Values of beta you just got above should be approximately same as the ones you got using multiple_linear_reg_model_gda.\n",
    "This assignment ends here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840bccaa",
   "metadata": {
    "id": "840bccaa"
   },
   "source": [
    "# Compute coefficients of determination\n",
    "\n",
    "We next compute the $R^2$ value for your hypothesis.\n",
    "\n",
    "To do this compute the following:\n",
    "*  $\\hat{y}$ for each training example (it should be one line of code if you use broadcasting)\n",
    "*  RSS\n",
    "*  TSS\n",
    "*  $R^2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72c0509",
   "metadata": {
    "id": "d72c0509"
   },
   "outputs": [],
   "source": [
    "# Write the code below\n",
    "# TODO Q13\n",
    "y_tr_pred = ...\n",
    "RSS = ...\n",
    "TSS = ...\n",
    "R2 = ...\n",
    "print(\"RSS = {0:f}\".format(RSS))\n",
    "print(\"TSS = {0:f}\".format(TSS))\n",
    "print(\"R^2 = {0:f}\".format(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y1Qd_mvrfgUw",
   "metadata": {
    "id": "Y1Qd_mvrfgUw"
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca8ce4",
   "metadata": {
    "id": "c0ca8ce4"
   },
   "source": [
    "# Optional (The following will not be graded):  \n",
    "# Stochastic Gradient Descent\n",
    "\n",
    "You can read more about stochastic gradient descent: https://en.wikipedia.org/wiki/Stochastic_gradient_descent\n",
    "\n",
    "To prevent cycles, shuffle the data for each pass.\n",
    "\n",
    "Write the code to perform a stochastic gradient descent. Remember, every update in a sgda uses examples one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089275c6",
   "metadata": {
    "id": "089275c6"
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X_1, y, learning_rate, w, N, num_iters):\n",
    "\n",
    "    for j in range(num_iters):\n",
    "    \n",
    "        for i in range(0,N):\n",
    "        # Write updated value of w\n",
    "            w = ...\n",
    "\n",
    "        if(j%2000==0):\n",
    "            cost= ...\n",
    "            print(\"Cost\")\n",
    "            print(cost)\n",
    "            print(\"w's\")\n",
    "            print(w)\n",
    "            \n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff97b3b",
   "metadata": {
    "id": "5ff97b3b"
   },
   "source": [
    "# Integrating the Stochastic Gradient Descent Algorithm\n",
    "\n",
    "Use this function to complete linear_reg_model_sgda(). This function uses stochastic gradient descent to minimize the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a2c46d",
   "metadata": {
    "id": "e7a2c46d"
   },
   "outputs": [],
   "source": [
    "def linear_reg_model_sgda(X_1, y, N, learning_rate, num_iters):\n",
    "    \n",
    "     #initialize the values of parameters w to be 0\n",
    "    w = ...\n",
    "    \n",
    "    #calculate the initial cost by calling the function cost you just coded above\n",
    "    print(\"Initial Cost\")\n",
    "    initial_cost= ...\n",
    "    print(initial_cost)\n",
    "    \n",
    "    #calculate the optimized value of w0 and w1 by calling the stochastic_gradient_descent function coded above\n",
    "    \n",
    "    w = ...\n",
    "    \n",
    "    #Calculate the cost with the optimized value of w0 and w1 by calling the cost function.\n",
    "    \n",
    "    final_cost= ...\n",
    "    print(\"Final_cost\")\n",
    "    print(final_cost)\n",
    "    return w, initial_cost, final_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388403e2",
   "metadata": {
    "id": "388403e2"
   },
   "outputs": [],
   "source": [
    "# Write your code below\n",
    "learning_rate = ...\n",
    "num_iters = ...\n",
    "# In place of None call the function linear_reg_model_sgda.\n",
    "results = ..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
